# sample_naive
arch:
  CRITIC_HAS_ACT_IND: False
  ACTIVATION:
    actor: Sin
    critic: Sin
  APPEND_DIM: 0
  LATENT_DIM: 0
  DIM_LIST:
    actor:  #! neurons for hidden layers
    - 256
    - 256
    - 256
    critic:  #! neurons for hidden layers
    - 128
    - 128
    - 128
  ACTION_RANGE:
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
  ACTION_DIM: 12  # the number of joints
  OBS_DIM: 36

environment:
  SEED: 0
  NUM_AGENTS: 1
  TIMEOUT: 2000
  END_CRITERION: failure

solver:
  USE_WANDB: False
  PROJECT_NAME: spirit-rl-pybullet
  NAME: spirit_naive_binary_f5_newStateDef
  OUT_FOLDER: spirit_naive_binary_f5_newStateDef
  CHECK_OPT_FREQ: 20
  SAVE_TOP_K: 50
  SAVE_METRIC: safety
  # train
  NUM_CPUS: 1
  MAX_STEPS: 6000000
  MEMORY_CAPACITY: 100000
  MIN_STEPS_B4_OPT: 20000
  OPTIMIZE_FREQ: 3000
  UPDATE_PER_OPT: 1000
  # eval
  NUM_EVAL_TRAJ: 100
  EVAL_TIMEOUT: 300
  NUM_ENVS: 1
  WARMUP_ACTION_RANGE:
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
  OBS_DIM: 36
  ROLLOUT_END_CRITERION: failure
  VENV_DEVICE: cpu

agent:
  DYN: SpiritPybullet
  FOOTPRINT: None
  VERBOSE: False
  GUI: False
  GUI_IMAGINARY: False
  DT: 0.02
  APPLY_FORCE: True
  REPLACE_ADV_WITH_DR: False # If True, this will replace the adversarial force with DR force
  FORCE: 5
  FORCE_SCALE: 1.0
  FORCE_RESET_TIME: 200
  FORCE_INFO:
  LINK_NAME: 
  ROTATE_RESET: True
  HEIGHT_RESET: True
  FORCE_RANDOM: True
  TERRAIN: normal
  TERRAIN_HEIGHT: 0.1
  TERRAIN_GRIDSIZE: 0.2
  TERRAIN_FRICTION: 1.0
  ENVTYPE: normal
  ACTION_RANGE:
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
    - [-0.5, 0.5]
  OBS_DIM: 36
  NUM_SEGMENT: 1
  AGENT_ID: ego
  RESET_CRITERION: failure
    
update:
  MAX_MODEL: 50
  ALPHA: 0.1
  LEARN_ALPHA: True
  BATCH_SIZE: 256
  DEVICE: cpu
  OPT_TYPE: AdamW
  GAMMA: 0.95
  GAMMA_DECAY: 0.5
  GAMMA_END: 0.995
  GAMMA_PERIOD: 500000
  GAMMA_SCHEDULE: False
  LATENT_DIM: 0
  LR_A: 0.0001
  LR_C: 0.0001
  LR_Al: 0.00005
  LR_A_END: 0.0001
  LR_C_END: 0.0001
  LR_Al_END: 0.00005
  LR_A_PERIOD: 50000
  LR_C_PERIOD: 50000
  LR_Al_PERIOD: 100000
  LR_A_DECAY: 0.9
  LR_C_DECAY: 0.9
  LR_Al_DECAY: 0.9
  LR_A_SCHEDULE: False
  LR_C_SCHEDULE: False
  LR_Al_SCHEDULE: False
  MODE: risk
  TAU: 0.01
  TERMINAL_TYPE: max
  EVAL: False
  UPDATE_PERIOD: 2 # of the actor
  ACTOR_TYPE: min

eval:
  MODEL_TYPE: manual # highest, safest, manual
  STEP: 1_100_000 # the step to use if "manual" is chosen for MODEL_TYPE
  EVAL_TIMEOUT: 1000 # how long do we evaluate in real rollout env
  IMAGINARY_HORIZON: 50 # the horizon of the imaginary env