# sample_naive
arch:
  CRITIC_HAS_ACT_IND: False
  ACTIVATION:
    actor: Sin
    critic: Sin
  APPEND_DIM: 0
  LATENT_DIM: 0
  DIM_LIST:
    actor_0:
    - 256
    - 256
    - 256
    actor_1:
    - 256
    - 256
    - 256
    critic:  #! neurons for hidden layers
    - 128
    - 128
    - 128
  ACTION_RANGE:
    - [ [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5],
        [-0.5, 0.5]
      ]
    - [ [-1., 1.],
        [-1., 1.],
        [-1., 1.],
        [-0.1, 0.1],
        [-0.1, 0.1],
        [0., 0.5],
      ]
  ACTION_DIM: [12, 6]  # the number of joints
  OBS_DIM: 
    actor_0: 36
    actor_1: 48
    critic: 36

environment:
  SEED: 0
  NUM_AGENTS: 2
  TIMEOUT: 2000
  END_CRITERION: failure

solver:
  USE_WANDB: False
  PROJECT_NAME: spirit-rl-pybullet
  NAME: spirit_isaacs_binary_f5_softmax_newStateDef_pretrained
  OUT_FOLDER: spirit_isaacs_binary_f5_softmax_newStateDef_pretrained
  CHECK_OPT_FREQ: 20
  SAVE_TOP_K: [50, 5]
  # train
  NUM_CPUS: 1
  MAX_STEPS: 8000000
  MEMORY_CAPACITY: 100000
  MIN_STEPS_B4_OPT: 20000
  OPTIMIZE_FREQ: 3000
  UPDATE_PER_OPT: [2000, 1000]
  CTRL_OPT_FREQ: 10
  MIN_STEPS_B4_EXPLOIT: 100000
  # eval
  NUM_EVAL_TRAJ: 100
  EVAL_TIMEOUT: 300
  NUM_ENVS: 1
  WARMUP_ACTION_RANGE:
    CTRL: 
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
    DSTB:
      - [-1., 1.]
      - [-1., 1.]
      - [-1., 1.]
      - [-0.1, 0.1]
      - [-0.1, 0.1]
      - [0., 0.5]
  OBS_DIM: 
    actor_0: 36
    actor_1: 48
    critic: 36
  ROLLOUT_END_CRITERION: failure
  VENV_DEVICE: cpu
  HISTORY_WEIGHT: 0.
  DSTB_SAMPLE_TYPE: softmax  # recent: uses the newest one; strongest: uses the strongest history
  INIT_DSTB_SAMPLE_TYPE: strongest
  DSTB_SAMPLE_CUR_WEIGHT: 0.  # only useful for "softmax", how many weights for the recent, and the history shares (1-weight)
  CHECK_NOM: False

agent:
  DYN: SpiritPybullet
  FOOTPRINT: None
  VERBOSE: False
  GUI: False
  GUI_IMAGINARY: False
  DT: 0.02
  APPLY_FORCE: True
  REPLACE_ADV_WITH_DR: False # If True, this will replace the adversarial force with DR force
  FORCE: 5
  FORCE_SCALE: 1.0
  FORCE_RESET_TIME: 200
  FORCE_INFO:
  LINK_NAME:
  ROTATE_RESET: True
  HEIGHT_RESET: True
  FORCE_RANDOM: True
  TERRAIN: normal
  TERRAIN_HEIGHT: 0.1
  TERRAIN_GRIDSIZE: 0.2
  TERRAIN_FRICTION: 1.0
  ENVTYPE: normal
  ACTION_RANGE:
    CTRL:
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
      - [-0.5, 0.5]
    DSTB:
      - [-1., 1.]
      - [-1., 1.]
      - [-1., 1.]
      - [-0.1, 0.1]
      - [-0.1, 0.1]
      - [0., 0.5]
  OBS_DIM: 
    actor_0: 36
    actor_1: 48
    critic: 36
  NUM_SEGMENT: 1
  AGENT_ID: ego
  PRETRAIN_CTRL: train_result/spirit_naive_avoidonly_f5_newStateDef/spirit_naive_avoidonly_f5_newStateDef_05/model/actor/actor-5960000.pth
  PRETRAIN_DSTB: train_result/spirit_dstb_naive_avoidonly_f5_newStateDef/spirit_dstb_naive_avoidonly_f5_newStateDef_05/model/actor/actor-1640000.pth
  RESET_CRITERION: failure

update:
  MAX_MODEL: 50
  ALPHA: [0.1, 0.1]
  LEARN_ALPHA: True
  BATCH_SIZE: 256
  DEVICE: cpu
  OPT_TYPE: AdamW
  GAMMA: 0.95
  GAMMA_DECAY: 0.5
  GAMMA_END: 0.995
  GAMMA_PERIOD: 500000
  GAMMA_SCHEDULE: False
  LATENT_DIM: 0
  LR_A: 0.0001
  LR_C: 0.0001
  LR_Al: [0.00005, 0.000025]
  LR_A_END: 0.0001
  LR_C_END: 0.0001
  LR_Al_END: 0.00005
  LR_A_PERIOD: 50000
  LR_C_PERIOD: 50000
  LR_Al_PERIOD: 100000
  LR_A_DECAY: 0.9
  LR_C_DECAY: 0.9
  LR_Al_DECAY: 0.9
  LR_A_SCHEDULE: False
  LR_C_SCHEDULE: False
  LR_Al_SCHEDULE: False
  MODE: risk
  TAU: 0.01
  TERMINAL_TYPE: max
  EVAL: False
  UPDATE_PERIOD: [2, 2] # of the actor
  ACTOR_TYPE: [min, max]

eval:
  MODEL_TYPE: [manual, highest] # [ctrl, dstb], highest, safest, worst, manual
  STEP: [7_580_000, 0] # [ctrl, dstb], the step to use if "manual" is chosen for MODEL_TYPE
  EVAL_TIMEOUT: 1000 # how long do we evaluate in real rollout env
  IMAGINARY_HORIZON: 300 # the horizon of the imaginary env